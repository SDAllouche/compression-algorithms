# Compression Algorithms 

## Introduction

On a human scale things happen very quickly. The speed of transmission is generally used to designate the exchange of information between computers or in general electronic devices as transmitter-telecommunications receiver and is considered a performance factor of the telecommunications system or electronic hardware device, particularly felt by the user as a Quality of Service parameter.

Compressed data is ubiquitous in the files you use frequently. For example, without data compression, a 4-minute song could be larger than 150 MB. Similarly, a 5-minute video would have a size that approaches 1 GB or more.

In this project, we will see some compression algorithms like (RLE, LZW, ...) using python.

1. RLE

La méthode de compression RLE (Run Length Encoding, parfois notée RLC pour Run Length Coding) est utilisée par de nombreux formats d'images (BMP, PCX, TIFF). Elle est basée sur la répétition d'éléments consécutifs.
Le principe de base consiste à : au lieu de répéter plusieurs fois un même symbole, on indique le nombre de fois qu’on le répète, puis ce symbole (une seule fois).

Ainsi selon ce principe :
* Chaîne à compressée est : "AAAAABBBBBB"
* Chaîne compressée : (A,5)(B,6)
* Ce qui conduit au code : 5 6
* Le gain de compression est ainsi : (11-2)/11 soit environ 81,8%

2. Huffman

Huffman’s coder creates an ordered tree from all symbols and their frequency of appearance. Branches are recursively constructed from the least common symbols.
The tree is built by first ordering the symbols by frequency of appearance.
Successively the two symbols of the lowest frequency of appearance are removed from the list and attached to a node whose weight is the sum of the frequencies of the two symbols. The lower-weight symbol is assigned to branch 1, the other to branch 0 and so on by considering each node formed as a new symbol, until you get a single parent node called root.
The code of each symbol corresponds to the sequence of codes along the path from this character to the root.

Or the text “PERSEVERANCE” to code, using Huffman’s technique:

![image](https://user-images.githubusercontent.com/102489525/231551150-95aa401e-f552-497f-a51c-6c22aabf914f.png)

## LZ78

The LZ78 features a temporary dictionary that is built at the encoder and decoder level in the same way.
The code words generated by the algorithm consist of two <index,symbol> elements (a label): the position of the longest previous subset prefix of the current subset, and the added character that makes the subset unique.
To do this, it operates as follows:
* A series of symbols of an A alphabet.
* Suppose that N symbols have already been read and a dictionary of words already read has been formed.
* From the (N+1) th symbol, read the symbols one by one until you get a word of length n not belonging to the dictionary, write the index of the last word recognized in the dictionary (length n-1) as well as the last symbol read.
* Add this new word (length n) to the dictionary and start again from (N+n+1) -th symbol.

## LZW

LZW (for Lempel-Ziv-Welch) is a lossless data compression algorithm. It is an improvement of the LZ78 algorithm invented by Abraham Lempel and Jacob Ziv in 1978. LZW was created in 1984 by Terry Welch, hence its name.

The compression algorithm builds a string translation table from the text to be compressed. This table links codes of fixed size (usually 12 bits) to strings. The table is initialized with all characters (256 entries in the case of 8-bit characters). As the compressor examines the text, it adds each 2-character string to the table as a concatenation of code and characters, with the code corresponding to the first character of the string. At the same time it records these strings, the first character is sent out. Each time a string already encountered is read, the longest string ever encountered is determined, and the code corresponding to that string with the concatenated character (the next character of the incoming stream) is recorded in the table. The code for the longest part of the encountered string is sent out and the last character is used as the base for the next string.

The decompression algorithm only needs the input compressed text. Indeed, it reconstructs an identical string/code table as it regenerates the original text. However, an unusual case occurs whenever the character/string/character/string/character sequence (with the same character for each character and the same string for each string) is encountered as input and that character/string is already present in the table. When the decompression algorithm reads the code for character/string/character, it cannot process it because it has not yet stored this code in the table. This particular case can be managed because the decompression program knows that the extra character is the previous character encountered.

* Example: Or the sequence to be encoded by LZW: "1001011100011100101".

![image](https://user-images.githubusercontent.com/102489525/231552295-e984bcaf-cd57-4771-bc61-01cab448b85a.png)


## License

[MIT License](License)



